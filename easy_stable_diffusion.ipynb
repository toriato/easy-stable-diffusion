{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1jw8kgDlyHY"
      },
      "source": [
        "[원본 코랩 주소](https://colab.research.google.com/drive/1nBaePtwcW_ds7OQdFebcxB91n_aORQY5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83yYK4Gh5AKI"
      },
      "source": [
        "## 실행하는 방법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVvqEyfk4VKk"
      },
      "source": [
        "- **중요**: 모바일에서 접속했다면 꼭 **데스크탑 보기**를 켤 것\n",
        "1. 상단 메뉴 중 `파일` > `드라이브에 사본 저장`\n",
        "1. `실행` 셀의 좌측에 있는 있는 *재생 아이콘* 클릭\n",
        "1. 조금 기다리면 웹 UI 주소 출력됨 (`https://xxxxxx.gradio.app`)\n",
        "  <br>처음 실행할 땐 이거 저거 받아와야해서 조금 오래 걸림...\n",
        "  <br>**빨간 오류 메세지**만 안뜨면 됨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XtKWLG8DIln"
      },
      "source": [
        "## 자주 하는 질문"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyUm9iWP4Xdc"
      },
      "source": [
        "\n",
        "\n",
        "- Q. `AssertionError: Torch is not able to use GPU...`\n",
        "  <br>A. GPU 못 찾아서 발생하는 오류, 코랩이면 GPU 런타임이 아니여서 발생하는 오류\n",
        "  <br>상단 `런타임` > `런타임 유형 변경` > `GPU`로 변경하고 재실행\n",
        "\n",
        "- Q. `백엔드를 할당하지 못했습니다. GPU이(가) 있는 백엔드를 사용할 수 없습니다...`\n",
        "  <br>구글 부계정 만들어서 로그인하고 시도하면 될거임\n",
        "  <br>코랩 Pro랑 Pro+ 전부 종량제로 바뀐 뒤로 돈낭비니까\n",
        "  <br>돈 내고 싶으면 가능한 [NovelAI](https://novelai.net/) 쓰거나 [vast.ai](https://vast.ai) 같은 싼 GPU 호스팅/렌탈 서비스 추천함\n",
        "\n",
        "- Q. **뭔가 안됨... 오류 뜨는데 잘 몰?루겠음...**\n",
        "  <br>A. [만든 놈 미니 갤러리](https://gall.dcinside.com/mini/board/lists/?id=owo) 또는 디스코드 `aeon#4285`\n",
        "\n",
        "- Q. **똥컴도 가능함?**\n",
        "  <br>A. 구글 서버 쓰는거고 결과만 보여주는거라 상관 없음\n",
        "\n",
        "- Q. **코랩 밖에서도 실행할 수 있음?**\n",
        "  <br>A. 테스트는 안해봤는데 아마 될거임... 구글 드라이브 연동만 제외하고\n",
        "\n",
        "- Q. **NAI 유출 모델 돌아감?**\n",
        "  <br>A. ㅇㅇ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJNoIIZxDLeb"
      },
      "source": [
        "## 참고 주소"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGtpoeBTDTB1"
      },
      "source": [
        "- https://rentry.org/voldy\n",
        "- https://rentry.org/sdmodels\n",
        "- https://cyberes.github.io/stable-diffusion-models/\n",
        "- https://github.com/AUTOMATIC1111/stable-diffusion-webui\n",
        "- https://public.vmm.pw/aeon/models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tB5NaiW4acE"
      },
      "source": [
        "### 국내 관련 커뮤니티\n",
        "\n",
        "- [아카라이브 AI그림 채널](https://arca.live/b/aiart)\n",
        "- [아카라이브 AI그림 채널 위키](https://arca.live/w/aiart/FrontPage)\n",
        "- [디시인사이드 AI 창작 마이너 갤러리](https://gall.dcinside.com/m/aicreate)\n",
        "- [디시인사이드 특이점이 온다 마이너 갤러리](https://gall.dcinside.com/m/thesingularity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW3fQ4sj48vY"
      },
      "source": [
        "## 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGSqtUJPJoOj"
      },
      "outputs": [],
      "source": [
        "# @title 실행하기\n",
        "# fmt: off\n",
        "from genericpath import isfile\n",
        "import os\n",
        "import sys\n",
        "import platform\n",
        "import re\n",
        "import glob\n",
        "import json\n",
        "from tkinter.messagebox import NO\n",
        "import requests\n",
        "from typing import Union, Callable, List\n",
        "from importlib.util import find_spec\n",
        "from pathlib import Path\n",
        "from shutil import rmtree\n",
        "from collections import Counter\n",
        "from IPython.display import display\n",
        "from ipywidgets import widgets\n",
        "\n",
        "def format_styles(styles: dict) -> str:\n",
        "    return ';'.join(map(lambda kv: ':'.join(kv), styles.items()))\n",
        "\n",
        "html_dialog = widgets.HTML()\n",
        "html_dialog_presets = {\n",
        "    'default': {\n",
        "        'display': 'inline-block',\n",
        "        'padding': '.5em',\n",
        "        'background-color': 'black',\n",
        "        'font-size': '1.25em',\n",
        "        'line-height': '1em',\n",
        "        'color': 'white',\n",
        "    },\n",
        "    'error': {\n",
        "        'border-left': '6px solid red'\n",
        "    }\n",
        "}\n",
        "\n",
        "html_logger_styles = {\n",
        "    'overflow-x': 'auto',\n",
        "    'max-width': '700px',\n",
        "    'padding': '1em',\n",
        "    'background-color': 'black',\n",
        "    'white-space': 'pre-wrap',\n",
        "    'font-family': 'monospace',\n",
        "    'font-size': '1em',\n",
        "    'line-height': '1em',\n",
        "    'color': 'white'\n",
        "}\n",
        "html_logger = widgets.HTML(\n",
        "    value=f'<div id=\"logger\" style=\"{format_styles(html_logger_styles)}\">')\n",
        "html_logger.raw = ''\n",
        "\n",
        "\n",
        "def dialog(msg, preset:str=None, styles=html_dialog_presets['default']) -> None:\n",
        "    if preset and preset in html_dialog_presets:\n",
        "        styles = {\n",
        "            **html_dialog_presets['default'],\n",
        "            **html_dialog_presets[preset],\n",
        "            **styles\n",
        "        }\n",
        "\n",
        "    html_dialog.value = f'<div style=\"{format_styles(styles)}\">{msg}</div>'\n",
        "\n",
        "\n",
        "def log(msg, newline=True, styles={}, bold=False) -> None:\n",
        "    if bold:\n",
        "        styles['font-weight'] = 'bold'\n",
        "\n",
        "    if newline:\n",
        "        msg += '\\n'\n",
        "\n",
        "    html_logger.raw += msg\n",
        "    html_logger.value += f'<span style=\"{format_styles(styles)}\">{msg}</span>'\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 서브 프로세스\n",
        "# ==============================\n",
        "running_subprocess = None\n",
        "\n",
        "\n",
        "def execute_subprocess(args: Union[str, List[str]], parser: Callable=None,\n",
        "                       throw=True, **kwargs) -> int:\n",
        "    global running_subprocess\n",
        "\n",
        "    # 이미 서브 프로세스가 존재한다면 예외 처리하기\n",
        "    if running_subprocess:\n",
        "        raise Exception('하위 프로세스가 실행되고 있습니다')\n",
        "\n",
        "    if isinstance(args, str):\n",
        "        log(f'=> {args}', styles={'color':'yellow'})\n",
        "    else:\n",
        "        log(f\"=> {' '.join(args)}\", styles={'color':'yellow'})\n",
        "\n",
        "    html_logger.value += '<div style=\"padding-left:1em\">'\n",
        "\n",
        "    # 서브 프로세스 만들기\n",
        "    from subprocess import Popen, PIPE, STDOUT\n",
        "    running_subprocess = Popen(\n",
        "        args,\n",
        "        stdout=PIPE,\n",
        "        stderr=STDOUT,\n",
        "        encoding='utf-8',\n",
        "        **kwargs,\n",
        "    )\n",
        "\n",
        "    running_subprocess.output = ''\n",
        "\n",
        "    # 프로세스 출력 위젯에 리다이렉션하기\n",
        "    while running_subprocess.poll() is None:\n",
        "        # 출력이 비어있다면 넘어가기\n",
        "        out = running_subprocess.stdout.readline()\n",
        "        if not out:\n",
        "            continue\n",
        "\n",
        "        # 프로세스 출력 버퍼에 추가하기\n",
        "        running_subprocess.output += out\n",
        "\n",
        "        # 파서가 없거나 또는 파서 실행 후 반환 값이 거짓이라면 로깅하기\n",
        "        if not parser or not parser(out):\n",
        "            log(out, newline=False, styles={'color': '#AAA'})\n",
        "\n",
        "    # 변수 정리하기\n",
        "    returncode = running_subprocess.poll()\n",
        "    running_subprocess = None\n",
        "\n",
        "    # 명령어 실행에 실패했다면 빨간 글씨로 표시하기\n",
        "    styles = {'color': 'green'}\n",
        "    if returncode != 0:\n",
        "        styles['color'] = 'red'\n",
        "\n",
        "    html_logger.value += '</div>'\n",
        "    log(f\"=> {returncode}\", styles=styles)\n",
        "\n",
        "    # 반환 코드가 정상이 아니라면 예외 발생하기\n",
        "    if returncode != 0 and throw:\n",
        "        raise Exception(f'프로세스가 {returncode} 코드를 반환했습니다')\n",
        "\n",
        "    return returncode\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 작업 경로\n",
        "# ==============================\n",
        "path_to = {\n",
        "    'packages': '/content/packages',\n",
        "    'repository': '/content/repository'\n",
        "}\n",
        "\n",
        "def update_path_to(path_to_workspace: str) -> None:\n",
        "    log(f'작업 공간 경로를 \"{path_to_workspace}\" 으로 변경했습니다')\n",
        "\n",
        "    path_to['workspace'] = path_to_workspace\n",
        "    path_to['outputs'] = f\"{path_to['workspace']}/outputs\"\n",
        "    path_to['models'] = f\"{path_to['workspace']}/models\"\n",
        "    path_to['embeddings'] = f\"{path_to['workspace']}/embeddings\"\n",
        "    path_to['ui_config_file'] = f\"{path_to['workspace']}/ui-config.json\"\n",
        "    path_to['ui_settings_file'] = f\"{path_to['workspace']}/config.json\"\n",
        "\n",
        "    os.makedirs(path_to['workspace'], exist_ok=True)\n",
        "    os.makedirs(path_to['packages'], exist_ok=True)\n",
        "    os.makedirs(path_to['embeddings'], exist_ok=True)\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 사용자 설정\n",
        "# ==============================\n",
        "CHECKPOINTS = {\n",
        "    # 'Standard Model 1.4': {\n",
        "    #   'files': [{'url': 'https://public.vmm.pw/aeon/models/sd-v1-4.ckpt'}]\n",
        "    # },\n",
        "\n",
        "    # NAI leaks\n",
        "    'NAI - animefull-final-pruned': {\n",
        "        'files': [\n",
        "            {\n",
        "                'url': 'https://anonfiles.com/n6h3Q0Bdyf',\n",
        "                'args': ['-o', 'nai-animefull-final-pruned.ckpt']\n",
        "            },\n",
        "            {\n",
        "                'url': 'https://anonfiles.com/66c1QcB7y6',\n",
        "                'args': ['-o', 'nai-animefull-final-pruned.vae.pt']\n",
        "            },\n",
        "            {\n",
        "                'url': 'https://gist.githubusercontent.com/toriato/ae1f587f4d1e9ee5d0e910c627277930/raw/6019f8782875497f6e5b3e537e30a75df5b64812/animefull-final-pruned.yaml',\n",
        "                'args': ['-o', 'nai-animefull-final-pruned.yaml']\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    'NAI - animefull-latest': {\n",
        "        'files': [\n",
        "            {\n",
        "                'url': 'https://anonfiles.com/8fm7QdB1y9',\n",
        "                'args': ['-o', 'nai-animefull-latest.ckpt']\n",
        "            },\n",
        "            {\n",
        "                'url': 'https://anonfiles.com/66c1QcB7y6',\n",
        "                'args': ['-o', 'nai-animefull-latest.vae.pt']\n",
        "            },\n",
        "            {\n",
        "                'url': 'https://gist.githubusercontent.com/toriato/ae1f587f4d1e9ee5d0e910c627277930/raw/6019f8782875497f6e5b3e537e30a75df5b64812/animefull-latest.yaml',\n",
        "                'args': ['-o', 'nai-animefull-latest.yaml']\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "\n",
        "    # Waifu stuffs\n",
        "    # 'Waifu Diffusion 1.2': {\n",
        "    #   'files': [{'url': 'https://public.vmm.pw/aeon/models/wd-v1-2-full-ema-pruned.ckpt'}]\n",
        "    # },\n",
        "    'Waifu Diffusion 1.3': {\n",
        "        'files': [{\n",
        "            'url': 'https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/wd-v1-3-float16.ckpt',\n",
        "            'args': ['-o', 'wd-v1-3-epoch09-float16.ckpt']\n",
        "        }]\n",
        "    },\n",
        "\n",
        "    # Trinart2\n",
        "    'Trinart Stable Diffusion v2 60,000 Steps': {\n",
        "        'files': [{'url': 'https://huggingface.co/naclbit/trinart_stable_diffusion_v2/resolve/main/trinart2_step60000.ckpt'}]\n",
        "    },\n",
        "    'Trinart Stable Diffusion v2 95,000 Steps': {\n",
        "        'files': [{'url': 'https://huggingface.co/naclbit/trinart_stable_diffusion_v2/resolve/main/trinart2_step95000.ckpt'}]\n",
        "    },\n",
        "    'Trinart Stable Diffusion v2 115,000 Steps': {\n",
        "        'files': [{'url': 'https://huggingface.co/naclbit/trinart_stable_diffusion_v2/resolve/main/trinart2_step115000.ckpt'}]\n",
        "    },\n",
        "\n",
        "    # Kinky c:\n",
        "    # 'gg1342_testrun1': {\n",
        "    #   'files': [{'url': 'https://public.vmm.pw/aeon/models/gg1342_testrun1_pruned.ckpt'}]\n",
        "    # },\n",
        "    # 'Hentai Diffusion RD1412': {\n",
        "    #   'files': [{\n",
        "    #     'url': 'https://public.vmm.pw/aeon/models/RD1412-pruned-fp16.ckpt',\n",
        "    #     'args': ['-o', 'hentai_diffusion-rd1412-pruned-fp32.ckpt']\n",
        "    #   }]\n",
        "    # },\n",
        "    # 'Bare Feet / Full Body b4_t16_noadd': {\n",
        "    #   'files': [{'url': 'https://public.vmm.pw/aeon/models/bf_fb_v3_t4_b16_noadd-ema-pruned-fp16.ckpt'}]\n",
        "    # },\n",
        "    # 'Lewd Diffusion 70k (epoch 2)': {\n",
        "    #   'files': [{'url': 'https://public.vmm.pw/aeon/models/LD-70k-2e-pruned.ckpt'}]\n",
        "    # },\n",
        "\n",
        "    # More kinky c:<\n",
        "    # 'Yiffy (epoch 18)': {\n",
        "    #   'files': [{'url': 'https://public.vmm.pw/aeon/models/yiffy-e18.ckpt'}]\n",
        "    # },\n",
        "    'Furry (epoch 4)': {\n",
        "        'files': [{'url': 'https://iwiftp.yerf.org/Furry/Software/Stable%20Diffusion%20Furry%20Finetune%20Models/Finetune%20models/furry_epoch4.ckpt'}]\n",
        "    },\n",
        "    'Zack3D Kinky v1': {\n",
        "        'files': [{'url': 'https://iwiftp.yerf.org/Furry/Software/Stable%20Diffusion%20Furry%20Finetune%20Models/Finetune%20models/Zack3D_Kinky-v1.ckpt'}]\n",
        "    },\n",
        "    # 'R34 (epoch 1)': {\n",
        "    #   'files': [{'url': 'https://public.vmm.pw/aeon/models/r34_e1.ckpt'}]\n",
        "    # },\n",
        "    # 'Pony Diffusion': {\n",
        "    #  'files': [{ 'url': 'https://public.vmm.pw/aeon/models/pony_sfw_80k_safe_and_suggestive_500rating_plus-pruned.ckpt'}]\n",
        "    # },\n",
        "    'Pokemon': {\n",
        "        'files': [{\n",
        "            'url': 'https://huggingface.co/justinpinkney/pokemon-stable-diffusion/resolve/main/ema-only-epoch%3D000142.ckpt',\n",
        "            'args': ['-o', 'pokemon-ema-pruned.ckpt']\n",
        "        }]\n",
        "    },\n",
        "\n",
        "    # Others...\n",
        "    'Dreambooth - Hiten': {\n",
        "        'files': [{'url': 'https://huggingface.co/BumblingOrange/Hiten/resolve/main/Hiten%20girl_anime_8k_wallpaper_4k.ckpt'}]\n",
        "    },\n",
        "}\n",
        "\n",
        "# @markdown ### ***체크포인트 모델 선택***\n",
        "# @markdown - [모델 별 설명 및 다운로드 주소](https://rentry.org/sdmodels)\n",
        "CHECKPOINT = 'NAI - animefull-final-pruned' # @param ['NAI - animefull-final-pruned', 'NAI - animefull-latest', 'Waifu Diffusion 1.3', 'Trinart Stable Diffusion v2 60,000 Steps', 'Trinart Stable Diffusion v2 95,000 Steps', 'Trinart Stable Diffusion v2 115,000 Steps', 'Furry (epoch 4)', 'Zack3D Kinky v1', 'Pokemon', 'Dreambooth - Hiten'] {allow-input: true}\n",
        "\n",
        "# @markdown ### ***구글 드라이브 동기화를 사용할건지?***\n",
        "USE_GOOGLE_DRIVE = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown ### ***구글 드라이브 경로***\n",
        "PATH_TO_GOOGLE_DRIVE = 'SD'  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### ***xformers 를 사용할지?***\n",
        "# @markdown 켜두면 10-15% 정도의 성능 향상을 ***보일 수도 있음***\n",
        "# @markdown <br>패키지를 직접 빌드하는데 30분에서 한 시간 정도 걸림\n",
        "# @markdown <br>구글 드라이브 동기화 아직 구현 안해둬서 개인 컴퓨터에서만 사용하는 걸 추천함\n",
        "USE_XFORMERS = False  # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown ### ***DeepDanbooru 를 사용할지?***\n",
        "USE_DEEPDANBOORU = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# 현재 코랩 환경에서 구동 중인지?\n",
        "IN_COLAB = find_spec('google.colab') is not None\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 패키지 준비\n",
        "# ==============================\n",
        "def prepare_aria2() -> None:\n",
        "    log('aria2 패키지를 설치합니다')\n",
        "    execute_subprocess(\n",
        "        ['apt', 'install', '-y', 'aria2'])\n",
        "\n",
        "    # 설정 파일 만들기\n",
        "    log('aria2 설정 파일을 만듭니다')\n",
        "    os.makedirs(os.path.join(Path.home(), '.aria2'), exist_ok=True)\n",
        "    with open(Path.joinpath(Path.home(), '.aria2', 'aria2.conf'), \"w\") as f:\n",
        "        f.write(\"\"\"\n",
        "summary-interval=10\n",
        "allow-overwrite=true\n",
        "always-resume=true\n",
        "disk-cache=64M\n",
        "continue=true\n",
        "min-split-size=8M\n",
        "max-concurrent-downloads=8\n",
        "max-connection-per-server=8\n",
        "max-overall-download-limit=0\n",
        "max-download-limit=0\n",
        "split=8\n",
        "seed-time=0\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 구글 드라이브 동기화\n",
        "# ==============================\n",
        "def mount_google_drive() -> None:\n",
        "    log('구글 드라이브 마운트를 시도합니다')\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "    # 전체 경로 업데이트\n",
        "    update_path_to(os.path.join('/content/drive/MyDrive', PATH_TO_GOOGLE_DRIVE))\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 파일 다운로드\n",
        "# ==============================\n",
        "def download(url: str, args=[]):\n",
        "    # anonfile CDN 주소 가져오기\n",
        "    if url.startswith('https://anonfiles.com/'):\n",
        "        matches = re.search('https://cdn-[^\\\"]+', requests.get(url).text)\n",
        "        if not matches:\n",
        "            raise Exception('anonfiles 에서 CDN 주소를 파싱하는데 실패했습니다')\n",
        "\n",
        "        url = matches[0]\n",
        "\n",
        "    # Aria2 로 모델 받기\n",
        "    log(f\"파일 다운로드를 시도합니다: {url}\")\n",
        "    execute_subprocess(['aria2c', *args, url])\n",
        "    log('파일을 성공적으로 받았습니다!')\n",
        "\n",
        "\n",
        "def download_checkpoint(checkpoint: str) -> None:\n",
        "    try:\n",
        "        prepare_aria2()\n",
        "\n",
        "        # 선택한 체크포인트 정보 가져오기\n",
        "        if checkpoint in CHECKPOINTS:\n",
        "            checkpoint = CHECKPOINTS[checkpoint]\n",
        "        else:\n",
        "            # 미리 선언된 체크포인트가 아니라면 주소로써 사용하기\n",
        "            checkpoint = {'files': [{'url': checkpoint}]}\n",
        "\n",
        "        # Aria2 로 모델 받기\n",
        "        # TODO: 토렌트 마그넷 주소 지원\n",
        "        log(f\"파일 {len(checkpoint['files'])}개를 받습니다\")\n",
        "\n",
        "        for f in checkpoint['files']:\n",
        "            file = json.loads(json.dumps(f))\n",
        "\n",
        "            if 'args' not in file:\n",
        "                file['args'] = []\n",
        "\n",
        "            # 모델 받을 기본 디렉터리 경로 잡아주기\n",
        "            if '-d' not in file['args']:\n",
        "                file['args'] = [\n",
        "                    '-d', f\"{path_to['models']}/Stable-diffusion\", *file['args']]\n",
        "\n",
        "            download(**file)\n",
        "\n",
        "    finally:\n",
        "        is_fetching_checkpoint = False\n",
        "\n",
        "\n",
        "def has_checkpoint() -> bool:\n",
        "    for p in Path(f\"{path_to['models']}/Stable-diffusion\").glob('**/*.ckpt'):\n",
        "        # aria2 로 받다만 파일은 무시하기\n",
        "        if os.path.isfile(f'{p}.aria2'):\n",
        "            continue\n",
        "\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 파이썬 패키지\n",
        "# ==============================\n",
        "def install_python_package(pkgs: List[str], args=['-I', '--progress-bar=off', '--prefer-binary'],\n",
        "                           skip_if_has_package:List[str]=None, persist=False) -> None:\n",
        "    # 존재한다면 스킵할 패키지가 존재하는지 확인하기\n",
        "    if skip_if_has_package and len(filter_installed_python_packages([skip_if_has_package])) < 1:\n",
        "        log(f'{pkgs} 패키지가 이미 존재합니다, 설치를 넘깁니다')\n",
        "        return\n",
        "\n",
        "    # 영구 유지할 패키지는 외부 패키지 디렉터리에 저장하기\n",
        "    if persist:\n",
        "        args = [*args, f\"--target={path_to['packages']}\"]\n",
        "\n",
        "    log(f'{pkgs} 패키지가 존재하지 않습니다, 설치를 시도합니다')\n",
        "\n",
        "    # execute_subprocess(['python', '-m', 'pip', 'install', '--upgrade', 'setuptools'])\n",
        "    execute_subprocess(['python', '-m', 'pip', 'install', *args, *pkgs])\n",
        "\n",
        "\n",
        "def installed_python_packages() -> List[str]:\n",
        "    pkgs = !python -m pip list | tail -n+3 | cut -d' ' -f1\n",
        "    return pkgs\n",
        "\n",
        "\n",
        "def filter_installed_python_packages(pkgs: List[str]) -> List[str]:\n",
        "    installed_pkgs = installed_python_packages()\n",
        "    return [\n",
        "        p for p in pkgs if\n",
        "        # 빈 줄 제외\n",
        "        not p == ''\n",
        "\n",
        "        # 주석 처리된 패키지 제외\n",
        "        and not p.startswith('#')\n",
        "\n",
        "        # 설치된 패키지 제외\n",
        "        and re.search('[a-zA-Z0-9-_]+', p)[0].replace('_', '-') not in installed_pkgs\n",
        "    ]\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# WebUI 레포지토리 및 종속 패키지 설치\n",
        "# ==============================\n",
        "def patch_webui_repository() -> None:\n",
        "    # 모델 용량이 너무 커서 코랩 메모리 할당량을 초과하면 프로세스를 강제로 초기화됨\n",
        "    # 이를 해결하기 위해선 모델 맵핑 위치를 VRAM으로 변경해줘야함\n",
        "    # Thanks to https://gist.github.com/td2sk/e32a39344537fb3cd756ef4abdd3d371\n",
        "    # TODO: 코랩에서만 발생하는 문제인지?\n",
        "    log('WebUI 패치 -> 모델 맵핑 위치를 변경합니다')\n",
        "    execute_subprocess([\n",
        "        'sed',\n",
        "        '-i',\n",
        "        '''s/map_location=\"cpu\"/map_location=torch.device(\"cuda\")/g''',\n",
        "        f\"{path_to['repository']}/modules/sd_models.py\"\n",
        "    ])\n",
        "\n",
        "\n",
        "def install_webui_dependencies() -> None:\n",
        "    log('WebUI 종속 패키지를 설치합니다')\n",
        "\n",
        "    # 코랩에선 필요 없으나 다른 환경에선 높은 확률로 설치 필요한 패키지들\n",
        "    execute_subprocess(\n",
        "        ['apt', 'install', '-y', 'build-essential', 'libgl1'])\n",
        "\n",
        "    # 설치된 PyTorch 가 최신 GPU 지원하지 않을 수 있기 때문에 최신 버전으로 받아주기\n",
        "    # install_python_package(\n",
        "    #     ['torch', 'torchvision'],\n",
        "    #     [\n",
        "    #         '--ignore-installed',\n",
        "    #         '--extra-index-url=https://download.pytorch.org/whl/cu116'\n",
        "    #     ],\n",
        "    #     skip_if_has_package='torch',\n",
        "    #     persist=True\n",
        "    # )\n",
        "\n",
        "    # xformers 패키지 설치하기\n",
        "    # https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Xformers\n",
        "    # if USE_XFORMERS and 'xformers' not in installed_python_packages():\n",
        "    #     cwd = f\"{path_to['repository']}/repositories/xformers\"\n",
        "\n",
        "    #     log('xformers 패키지를 수동으로 설치합니다, 레포지토리를 가져옵니다')\n",
        "    #     rmtree('xformers', ignore_errors=True)\n",
        "    #     execute_subprocess(['git', 'clone', 'https://github.com/facebookresearch/xformers.git', cwd])\n",
        "    #     execute_subprocess(['git', 'submodule', 'update', '--init', '--recursive'], cwd=cwd)\n",
        "    #     execute_subprocess(['python', '-m', 'pip', 'install', '-r', 'requirements.txt'], cwd=cwd)\n",
        "\n",
        "    #     log('xformers 패키지를 빌드하고 설치합니다')\n",
        "    #     execute_subprocess(['python', '-m', 'pip', 'install', 'setuptools==49.6.0'])\n",
        "    #     execute_subprocess(['python', 'setup.py', 'install'], cwd=cwd)\n",
        "\n",
        "\n",
        "def setup_webui() -> None:\n",
        "    need_clone = True\n",
        "\n",
        "    # 이미 디렉터리가 존재한다면 정상적인 레포인지 확인하기\n",
        "    if os.path.isdir(path_to['repository']):\n",
        "        try:\n",
        "            log('WebUI 레포지토리를 풀(업데이트) 합니다')\n",
        "\n",
        "            # 사용자 파일만 남겨두고 레포지토리 초기화하기\n",
        "            # https://stackoverflow.com/a/12096327\n",
        "            execute_subprocess(['git', 'add', '-f', 'scripts', 'repositories'], cwd=path_to['repository'])\n",
        "            execute_subprocess(['git', 'checkout', '.'], cwd=path_to['repository'])\n",
        "            execute_subprocess(['git', 'pull'], cwd=path_to['repository'])\n",
        "            patch_webui_repository()\n",
        "\n",
        "        except:\n",
        "            log('레포지토리가 잘못됐습니다, 디렉터리를 제거합니다')\n",
        "\n",
        "    if need_clone:\n",
        "        log('WebUI 레포지토리를 클론합니다')\n",
        "        rmtree(path_to['repository'], ignore_errors=True)\n",
        "        execute_subprocess(['git', 'clone', 'https://github.com/AUTOMATIC1111/stable-diffusion-webui', path_to['repository']])\n",
        "\n",
        "    install_webui_dependencies()\n",
        "\n",
        "\n",
        "def parse_webui_output(out: str) -> bool:\n",
        "    matches = re.search('https://\\d+\\.gradio\\.app', out)\n",
        "    if matches:\n",
        "        log('******************************************', styles={'color':'green'})\n",
        "        log(f'성공적으로 웹UI를 실행했습니다, 아래 주소에 접속해주세요!\\n{matches[0]}',\n",
        "            styles={\n",
        "                'background-color': 'green',\n",
        "                'font-weight': 'bold',\n",
        "                'font-size': '1.5em',\n",
        "                'line-height': '1.5em',\n",
        "                'color': 'black'\n",
        "            })\n",
        "        log('******************************************', styles={'color':'green'})\n",
        "\n",
        "        dialog(f'''\n",
        "        <p>성공적으로 웹UI를 실행했습니다!</p>\n",
        "        <p><a target=\"_blank\" href=\"{matches[0]}\">{matches[0]}</a></p>\n",
        "        ''')\n",
        "\n",
        "\n",
        "def start_webui(args: List[str]=[], env={}) -> None:\n",
        "    global running_subprocess\n",
        "\n",
        "    if running_subprocess is not None:\n",
        "        if 'launch.py' in running_subprocess.args:\n",
        "            log('이미 실행 중인 웹UI를 종료하고 다시 시작합니다')\n",
        "            running_subprocess.kill()\n",
        "            running_subprocess = None\n",
        "\n",
        "        raise ('이미 다른 프로세스가 실행 중입니다, 잠시 후에 실행해주세요')\n",
        "\n",
        "    execute_subprocess(\n",
        "        ['python', 'launch.py', *args],\n",
        "        parser=parse_webui_output,\n",
        "        cwd=path_to['repository'],\n",
        "        env={\n",
        "            **os.environ,\n",
        "            'PYTHONUNBUFFERED': '1',\n",
        "            'REQS_FILE': 'requirements.txt',\n",
        "            **env\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 보고서\n",
        "# ==============================\n",
        "def generate_report() -> str:\n",
        "    import traceback\n",
        "    from distutils.spawn import find_executable\n",
        "\n",
        "    packages = !pip freeze\n",
        "    packages_310 = !python -m pip freeze\n",
        "\n",
        "    ex_type, ex_value, ex_traceback = sys.exc_info()\n",
        "    traces = map(lambda v: f'{v[0]}#{v[1]}\\n\\t{v[2]}\\n\\t{v[3]}', traceback.extract_tb(ex_traceback))\n",
        "\n",
        "    def format_list(value):\n",
        "        if isinstance(value, dict):\n",
        "            return '\\n'.join(map(lambda kv: f'{kv[0]}: {kv[1]}', value.items()))\n",
        "        else:\n",
        "            return '\\n'.join(value)\n",
        "\n",
        "    payload = f\"\"\"\n",
        "{html_logger.raw}\n",
        "# {ex_type.__name__}: {ex_value}\n",
        "{format_list(traces)}\n",
        "\n",
        "# platform\n",
        "{platform.platform()}\n",
        "\n",
        "# options\n",
        "CHECKPOINT: {CHECKPOINT}\n",
        "USE_GOOGLE_DRIVE: {USE_GOOGLE_DRIVE}\n",
        "PATH_TO_GOOGLE_DRIVE: {PATH_TO_GOOGLE_DRIVE}\n",
        "USE_XFORMERS: {USE_XFORMERS}\n",
        "USE_DEEPDANBOORU: {USE_DEEPDANBOORU}\n",
        "\n",
        "# paths\n",
        "{format_list(path_to)}\n",
        "\n",
        "# models\n",
        "{format_list(glob.glob(f\"{path_to['models']}/**/*\"))}\n",
        "\n",
        "# {sys.executable}\n",
        "{format_list(packages)}\n",
        "\n",
        "# {find_executable('python')}\n",
        "{format_list(packages_310)}\n",
        "\"\"\"\n",
        "\n",
        "    res = requests.post('https://hastebin.com/documents',\n",
        "                        data=payload.encode('utf-8'))\n",
        "\n",
        "    return f\"https://hastebin.com/{json.loads(res.text)['key']}\"\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 자 드게제~\n",
        "# ==============================\n",
        "try:\n",
        "    # 코랩 폼 입력 란을 생성을 위한 코드\n",
        "    # log(', '.join(map(lambda s:f\"'{s}'\", CHECKPOINTS.keys())))\n",
        "\n",
        "    # 기본 작업 경로 설정\n",
        "    update_path_to(os.curdir)\n",
        "\n",
        "    if IN_COLAB:\n",
        "        log('코랩 환경이 감지됐습니다')\n",
        "\n",
        "        import torch\n",
        "        assert torch.cuda.is_available(), 'GPU 가 없습니다, 런타임 유형이 잘못됐거나 GPU 할당량이 초과된 것 같습니다'\n",
        "\n",
        "        # 코랩 환경이라면 /content 디렉터리는 스토리지 속도가 느리기 때문에\n",
        "        # /usr/local 속에서 구동할 필요가 있음\n",
        "        log('레포지토리 디렉터리를 \"/usr/local/repository\" 로 변경합니다')\n",
        "        path_to['repository'] = '/usr/local/repository'\n",
        "\n",
        "        # 구글 드라이브 마운팅 시도\n",
        "        if USE_GOOGLE_DRIVE:\n",
        "            mount_google_drive()\n",
        "\n",
        "    # 인터페이스 출력\n",
        "    btn_download_checkpoint = widgets.Button(description='체크포인트 받기')\n",
        "    btn_download_checkpoint.on_click(\n",
        "        lambda _: download_checkpoint(CHECKPOINT)\n",
        "    )\n",
        "\n",
        "    display(\n",
        "        widgets.VBox([\n",
        "            btn_download_checkpoint,\n",
        "            html_dialog,\n",
        "            html_logger\n",
        "        ])\n",
        "    )\n",
        "\n",
        "    # 구동 필수 패키지 준비\n",
        "    prepare_aria2()\n",
        "\n",
        "    # 이후 아카이브 전 변경 여부 확인을 위해 현재 패키지 목록 받아두기\n",
        "    packages = Counter(installed_python_packages())\n",
        "\n",
        "    # 체크포인트가 없을 시 다운로드\n",
        "    if not has_checkpoint():\n",
        "        download_checkpoint(CHECKPOINT)\n",
        "\n",
        "    # WebUI 가져오기\n",
        "    setup_webui()\n",
        "\n",
        "    # WebUI 기본 설정 적용\n",
        "    with open(path_to['ui_config_file'], 'w+') as file:\n",
        "        configs = {\n",
        "            # NAI 기본 설정(?)\n",
        "            'txt2img/Prompt/value': 'best quality, masterpiece',\n",
        "            'txt2img/Negative prompt/value': 'lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry',\n",
        "            'txt2img/Sampling Steps/value': 28,\n",
        "            'txt2img/Width/value': 512,\n",
        "            'txt2img/Height/value': 768,\n",
        "            'txt2img/CFG Scale/value': 12,\n",
        "        }\n",
        "\n",
        "        # 기존 설정 우선으로 사용하기\n",
        "        try:\n",
        "            configs = { **configs, **json.loads(file.read()) }\n",
        "        except ValueError:\n",
        "            pass\n",
        "\n",
        "        file.write(json.dumps(configs, indent=4))\n",
        "\n",
        "    with open(path_to['ui_settings_file'], 'w+') as file:\n",
        "        configs = {\n",
        "            'save_txt': True,\n",
        "\n",
        "            # 결과 이미지 디렉터리\n",
        "            'outdir_txt2img_samples': f\"{path_to['outputs']}/txt2img-samples\",\n",
        "            'outdir_img2img_samples': f\"{path_to['outputs']}/img2img-samples\",\n",
        "            'outdir_extras_samples': f\"{path_to['outputs']}/extras-samples\",\n",
        "            'outdir_txt2img_grids': f\"{path_to['outputs']}/txt2img-grids\",\n",
        "            'outdir_img2img_grids': f\"{path_to['outputs']}/img2img-grids\",\n",
        "\n",
        "            # NAI 기본 설정(?)\n",
        "            'eta_ancestral': 0.2,\n",
        "            'CLIP_stop_at_last_layers': 2,\n",
        "        }\n",
        "\n",
        "        # 기존 설정 우선으로 사용하기\n",
        "        try:\n",
        "            configs = { **configs, **json.loads(file.read()) }\n",
        "        except ValueError:\n",
        "            pass\n",
        "\n",
        "        file.write(json.dumps(configs, indent=4))\n",
        "\n",
        "    # WebUI 실행\n",
        "    args = [\n",
        "        '--share',\n",
        "        '--gradio-debug',\n",
        "\n",
        "        # 동적 경로들\n",
        "        f\"--ckpt-dir={path_to['models']}/Stable-diffusion\",\n",
        "        f\"--embeddings-dir={path_to['embeddings']}\",\n",
        "        f\"--hypernetwork-dir={path_to['models']}/hypernetworks\",\n",
        "        f\"--codeformer-models-path={path_to['models']}/Codeformer\",\n",
        "        f\"--gfpgan-models-path={path_to['models']}/GFPGAN\",\n",
        "        f\"--esrgan-models-path={path_to['models']}/ESRGAN\",\n",
        "        f\"--bsrgan-models-path={path_to['models']}/BSRGAN\",\n",
        "        f\"--realesrgan-models-path={path_to['models']}/RealESRGAN\",\n",
        "        f\"--scunet-models-path={path_to['models']}/ScuNET\",\n",
        "        f\"--swinir-models-path={path_to['models']}/SwinIR\",\n",
        "        f\"--ldsr-models-path={path_to['models']}/LDSR\",\n",
        "\n",
        "        f\"--ui-config-file={path_to['ui_config_file']}\",\n",
        "        f\"--ui-settings-file={path_to['ui_settings_file']}\",\n",
        "    ]\n",
        "\n",
        "    cmd_args = [ '--skip-torch-cuda-test' ]\n",
        "\n",
        "    if USE_XFORMERS:\n",
        "        cmd_args = [*cmd_args, '--xformers']\n",
        "\n",
        "    if USE_DEEPDANBOORU:\n",
        "        cmd_args = [*cmd_args, '--deepdanbooru']\n",
        "\n",
        "    start_webui(args, env={'COMMANDLINE_ARGS': ' '.join(cmd_args)})\n",
        "\n",
        "# ^c 종료 무시하기\n",
        "except KeyboardInterrupt:\n",
        "    pass\n",
        "\n",
        "# 오류 발생하면 보고서 생성하고 표시하기\n",
        "except:\n",
        "    _, ex_value, _ = sys.exc_info()\n",
        "    report_url = generate_report()\n",
        "\n",
        "    log('******************************************', styles={'color':'red'})\n",
        "    log(f'오류가 발생했습니다, 아래 주소를 복사해 보고해주세요!\\n{report_url}',\n",
        "        styles={\n",
        "            'background-color': 'red',\n",
        "            'font-weight': 'bold',\n",
        "            'font-size': '1.5em',\n",
        "            'line-height': '1.5em',\n",
        "            'color': 'black'\n",
        "        })\n",
        "    log('******************************************', styles={'color':'red'})\n",
        "    log(f'{ex_value}', styles={'color':'red'})\n",
        "\n",
        "    dialog(\n",
        "        f'''\n",
        "        <p>오류가 발생했습니다, 아래 주소를 복사해 보고해주세요!</p>\n",
        "        <p><strong>{generate_report()}</strong></p>\n",
        "        ''',\n",
        "        preset='error'\n",
        "    )\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "2XtKWLG8DIln",
        "jJNoIIZxDLeb"
      ],
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
