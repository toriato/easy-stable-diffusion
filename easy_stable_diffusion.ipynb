{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1jw8kgDlyHY"
      },
      "source": [
        "[원본 코랩 주소](https://colab.research.google.com/drive/1nBaePtwcW_ds7OQdFebcxB91n_aORQY5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83yYK4Gh5AKI"
      },
      "source": [
        "## 실행하는 방법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVvqEyfk4VKk"
      },
      "source": [
        "- **중요**: 모바일에서 접속했다면 꼭 **데스크탑 보기**를 켤 것\n",
        "1. 상단 메뉴 중 `파일` > `드라이브에 사본 저장`\n",
        "1. `실행` 셀의 좌측에 있는 있는 *재생 아이콘* 클릭\n",
        "1. 조금 기다리면 웹 UI 주소 출력됨 (`https://xxxxxx.gradio.app`)\n",
        "  <br>처음 실행할 땐 이거 저거 받아와야해서 조금 오래 걸림...\n",
        "  <br>**빨간 오류 메세지**만 안뜨면 됨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XtKWLG8DIln"
      },
      "source": [
        "## 자주 하는 질문"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyUm9iWP4Xdc"
      },
      "source": [
        "\n",
        "\n",
        "- Q. `AssertionError: Torch is not able to use GPU...`\n",
        "  <br>A. GPU 못 찾아서 발생하는 오류, 코랩이면 GPU 런타임이 아니여서 발생하는 오류\n",
        "  <br>상단 `런타임` > `런타임 유형 변경` > `GPU`로 변경하고 재실행\n",
        "\n",
        "- Q. `백엔드를 할당하지 못했습니다. GPU이(가) 있는 백엔드를 사용할 수 없습니다...`\n",
        "  <br>구글 부계정 만들어서 로그인하고 시도하면 될거임\n",
        "  <br>코랩 Pro랑 Pro+ 전부 종량제로 바뀐 뒤로 돈낭비니까\n",
        "  <br>돈 내고 싶으면 가능한 [NovelAI](https://novelai.net/) 쓰거나 [vast.ai](https://vast.ai) 같은 싼 GPU 호스팅/렌탈 서비스 추천함\n",
        "\n",
        "- Q. **뭔가 안됨... 오류 뜨는데 잘 몰?루겠음...**\n",
        "  <br>A. [만든 놈 미니 갤러리](https://gall.dcinside.com/mini/board/lists/?id=owo) 또는 디스코드 `aeon#4285`\n",
        "\n",
        "- Q. **똥컴도 가능함?**\n",
        "  <br>A. 구글 서버 쓰는거고 결과만 보여주는거라 상관 없음\n",
        "\n",
        "- Q. **코랩 밖에서도 실행할 수 있음?**\n",
        "  <br>A. 테스트는 안해봤는데 아마 될거임... 구글 드라이브 연동만 제외하고\n",
        "\n",
        "- Q. **NAI 유출 모델 돌아감?**\n",
        "  <br>A. ㅇㅇ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJNoIIZxDLeb"
      },
      "source": [
        "## 참고 주소"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGtpoeBTDTB1"
      },
      "source": [
        "- https://rentry.org/voldy\n",
        "- https://rentry.org/sdmodels\n",
        "- https://cyberes.github.io/stable-diffusion-models/\n",
        "- https://github.com/AUTOMATIC1111/stable-diffusion-webui\n",
        "- https://public.vmm.pw/aeon/models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tB5NaiW4acE"
      },
      "source": [
        "### 국내 관련 커뮤니티\n",
        "\n",
        "- [아카라이브 AI그림 채널](https://arca.live/b/aiart)\n",
        "- [아카라이브 AI그림 채널 위키](https://arca.live/w/aiart/FrontPage)\n",
        "- [디시인사이드 AI 창작 마이너 갤러리](https://gall.dcinside.com/m/aicreate)\n",
        "- [디시인사이드 특이점이 온다 마이너 갤러리](https://gall.dcinside.com/m/thesingularity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW3fQ4sj48vY"
      },
      "source": [
        "## 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGSqtUJPJoOj"
      },
      "outputs": [],
      "source": [
        "# @title 실행하기\n",
        "# fmt: off\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import shutil\n",
        "import re\n",
        "import glob\n",
        "import json\n",
        "import requests\n",
        "from typing import Union, Callable, List\n",
        "from os.path import isdir, isfile, islink\n",
        "from pathlib import Path\n",
        "from IPython.display import display\n",
        "from ipywidgets import widgets\n",
        "\n",
        "dialog_presets = {\n",
        "    'default': {\n",
        "        'display': 'inline-block',\n",
        "        'padding': '.5em',\n",
        "        'background-color': 'black',\n",
        "        'font-size': '1.25em',\n",
        "        'line-height': '1em',\n",
        "        'color': 'white',\n",
        "    },\n",
        "    'error': {\n",
        "        'border-left': '6px solid red'\n",
        "    }\n",
        "}\n",
        "\n",
        "html_dialog = widgets.HTML()\n",
        "\n",
        "html_logger = widgets.HTML(value='''\n",
        "<div style=\"padding:1em;background-color:black;font-family:monospace;font-size:14px;line-height:14px;color:white\">\n",
        "''')\n",
        "html_logger.raw = ''\n",
        "\n",
        "\n",
        "def dialog(msg, preset:str=None, styles=dialog_presets['default']) -> None:\n",
        "    if preset and preset in dialog_presets:\n",
        "        styles = {\n",
        "            **dialog_presets['default'],\n",
        "            **dialog_presets[preset],\n",
        "            **styles\n",
        "        }\n",
        "\n",
        "    html_dialog.value = f\"\"\"\n",
        "    <div style=\"{';'.join(map(lambda kv: ':'.join(kv), styles.items()))}\">\n",
        "      {msg}\n",
        "    </div>\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "def log(msg, newline=True, styles={}, bold=False) -> None:\n",
        "    if bold:\n",
        "        styles['font-weight'] = 'bold'\n",
        "\n",
        "    if newline:\n",
        "        msg += '\\n'\n",
        "\n",
        "    msg_html = msg.replace('\\n', '<br>')\n",
        "\n",
        "    html_logger.raw += msg\n",
        "    html_logger.value += f\"\"\"\n",
        "    <span style=\"{';'.join(map(lambda kv: ':'.join(kv), styles.items()))}\">\n",
        "      {msg_html}\n",
        "    </span>\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 서브 프로세스\n",
        "# ==============================\n",
        "running_subprocess = None\n",
        "\n",
        "\n",
        "def execute_subprocess(args:Union[str, List[str]], parser:Callable=None, throw=True, **kwargs) -> int:\n",
        "    global running_subprocess\n",
        "\n",
        "    # 이미 서브 프로세스가 존재한다면 예외 처리하기\n",
        "    if running_subprocess:\n",
        "        raise Exception('하위 프로세스가 실행되고 있습니다')\n",
        "\n",
        "    if isinstance(args, str):\n",
        "        log(f'>>> {args}', styles={'color':'yellow'})\n",
        "    else:\n",
        "        log(f\">>> {' '.join(args)}\", styles={'color':'yellow'})\n",
        "\n",
        "    html_logger.value += '<div style=\"padding-left:1em\">'\n",
        "\n",
        "    # 서브 프로세스 만들기\n",
        "    running_subprocess = subprocess.Popen(\n",
        "        args,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        encoding='utf-8',\n",
        "        **kwargs,\n",
        "    )\n",
        "\n",
        "    running_subprocess.output = ''\n",
        "\n",
        "    # 프로세스 출력 위젯에 리다이렉션하기\n",
        "    while running_subprocess.poll() is None:\n",
        "        # 출력이 비어있다면 넘어가기\n",
        "        out = running_subprocess.stdout.readline()\n",
        "        if not out:\n",
        "            continue\n",
        "\n",
        "        # 프로세스 출력 버퍼에 추가하기\n",
        "        running_subprocess.output += out\n",
        "\n",
        "        # 파서가 없거나 또는 파서 실행 후 반환 값이 거짓이라면 로깅하기\n",
        "        if not parser or not parser(out):\n",
        "            log(out, newline=False, styles={'color': '#AAA'})\n",
        "\n",
        "    # 변수 정리하기\n",
        "    returncode = running_subprocess.poll()\n",
        "    running_subprocess = None\n",
        "\n",
        "    # 명령어 실행에 실패했다면 빨간 글씨로 표시하기\n",
        "    styles = {'color': 'green'}\n",
        "    if returncode != 0:\n",
        "        styles['color'] = 'red'\n",
        "\n",
        "    html_logger.value += '</div>'\n",
        "    log(f\">>> {returncode}\", styles=styles)\n",
        "\n",
        "    # 반환 코드가 정상이 아니라면 예외 발생하기\n",
        "    if returncode != 0 and throw:\n",
        "        raise Exception(f'프로세스가 {returncode} 코드를 반환했습니다')\n",
        "\n",
        "    return returncode\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 작업 경로\n",
        "# ==============================\n",
        "path_to = {'packages': '/content/packages'}\n",
        "\n",
        "# 파이썬 패키지 경로 추가하기\n",
        "if path_to['packages'] not in os.environ['PYTHONPATH']:\n",
        "    os.environ['PYTHONPATH'] = f\"{path_to['packages']}:{os.environ['PYTHONPATH']}\"\n",
        "\n",
        "\n",
        "def update_path_to(path_to_workspace:str) -> None:\n",
        "    log(f'작업 공간 경로를 \"{path_to_workspace}\" 으로 변경했습니다')\n",
        "\n",
        "    path_to['workspace'] = path_to_workspace\n",
        "    path_to['repo'] = f\"{path_to['workspace']}/repo\"\n",
        "    path_to['outputs'] = f\"{path_to['workspace']}/outputs\"\n",
        "    path_to['models'] = f\"{path_to['workspace']}/models\"\n",
        "    path_to['embeddings'] = f\"{path_to['workspace']}/embeddings\"\n",
        "    path_to['ui_config_file'] = f\"{path_to['workspace']}/ui-config.json\"\n",
        "    path_to['ui_settings_file'] = f\"{path_to['workspace']}/config.json\"\n",
        "\n",
        "    os.makedirs(path_to['workspace'], exist_ok=True)\n",
        "    os.makedirs(path_to['packages'], exist_ok=True)\n",
        "    os.makedirs(path_to['embeddings'], exist_ok=True)\n",
        "\n",
        "\n",
        "# 기본 작업 경로 설정\n",
        "update_path_to('/content')\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 사용자 설정\n",
        "# ==============================\n",
        "nai_hypernetwork_base = {'args': ['-d', f\"{path_to['models']}/hypernetworks\"]}\n",
        "nai_hypernetworks = [\n",
        "    # {**nai_hypernetwork_base, 'url': 'https://huggingface.co/FantasmaPersiana/basicalfamodel1-0/resolve/main/module/module/aini.pt'},\n",
        "    # {**nai_hypernetwork_base, 'url': 'https://huggingface.co/FantasmaPersiana/basicalfamodel1-0/resolve/main/module/module/anime.pt'},\n",
        "    # {**nai_hypernetwork_base, 'url': 'https://huggingface.co/FantasmaPersiana/basicalfamodel1-0/resolve/main/module/module/anime_2.pt'},\n",
        "    # {**nai_hypernetwork_base, 'url': 'https://huggingface.co/FantasmaPersiana/basicalfamodel1-0/resolve/main/module/module/anime_3.pt'},\n",
        "    # {**nai_hypernetwork_base, 'url': 'https://huggingface.co/FantasmaPersiana/basicalfamodel1-0/resolve/main/module/module/furry.pt'},\n",
        "    # {**nai_hypernetwork_base, 'url': 'https://huggingface.co/FantasmaPersiana/basicalfamodel1-0/resolve/main/module/module/furry_2.pt'},\n",
        "    # {**nai_hypernetwork_base, 'url': 'https://huggingface.co/FantasmaPersiana/basicalfamodel1-0/resolve/main/module/module/furry_3.pt'},\n",
        "    # {**nai_hypernetwork_base, 'url': 'https://huggingface.co/FantasmaPersiana/basicalfamodel1-0/resolve/main/module/module/furry_kemono.pt'},\n",
        "    # {**nai_hypernetwork_base, 'url': 'https://huggingface.co/FantasmaPersiana/basicalfamodel1-0/resolve/main/module/module/furry_protogen.pt'},\n",
        "    # {**nai_hypernetwork_base, 'url': 'https://huggingface.co/FantasmaPersiana/basicalfamodel1-0/resolve/main/module/module/furry_scalie.pt'},\n",
        "    # {**nai_hypernetwork_base, 'url': 'https://huggingface.co/FantasmaPersiana/basicalfamodel1-0/resolve/main/module/module/furry_transformation.pt'},\n",
        "    # {**nai_hypernetwork_base, 'url': 'https://huggingface.co/FantasmaPersiana/basicalfamodel1-0/resolve/main/module/module/pony.pt'},\n",
        "]\n",
        "\n",
        "CHECKPOINTS = {\n",
        "    # 'Standard Model 1.4': {\n",
        "    #   'files': [{'url': 'https://public.vmm.pw/aeon/models/sd-v1-4.ckpt'}]\n",
        "    # },\n",
        "\n",
        "    # NAI leaks\n",
        "    'NAI - animefull-final-pruned': {\n",
        "        'files': [\n",
        "            {\n",
        "                'url': 'https://anonfiles.com/n6h3Q0Bdyf',\n",
        "                'args': ['-o', 'nai-animefull-final-pruned.ckpt']\n",
        "            },\n",
        "            {\n",
        "                'url': 'https://anonfiles.com/66c1QcB7y6',\n",
        "                'args': ['-o', 'nai-animefull-final-pruned.vae.pt']\n",
        "            },\n",
        "            {\n",
        "                'url': 'https://gist.githubusercontent.com/toriato/ae1f587f4d1e9ee5d0e910c627277930/raw/6019f8782875497f6e5b3e537e30a75df5b64812/animefull-final-pruned.yaml',\n",
        "                'args': ['-o', 'nai-animefull-final-pruned.yaml']\n",
        "            }\n",
        "        ] + nai_hypernetworks\n",
        "    },\n",
        "    'NAI - animefull-latest': {\n",
        "        'files': [\n",
        "            {\n",
        "                'url': 'https://anonfiles.com/8fm7QdB1y9',\n",
        "                'args': ['-o', 'nai-animefull-latest.ckpt']\n",
        "            },\n",
        "            {\n",
        "                'url': 'https://anonfiles.com/66c1QcB7y6',\n",
        "                'args': ['-o', 'nai-animefull-latest.vae.pt']\n",
        "            },\n",
        "            {\n",
        "                'url': 'https://gist.githubusercontent.com/toriato/ae1f587f4d1e9ee5d0e910c627277930/raw/6019f8782875497f6e5b3e537e30a75df5b64812/animefull-latest.yaml',\n",
        "                'args': ['-o', 'nai-animefull-latest.yaml']\n",
        "            }\n",
        "        ] + nai_hypernetworks\n",
        "    },\n",
        "\n",
        "    # Waifu stuffs\n",
        "    # 'Waifu Diffusion 1.2': {\n",
        "    #   'files': [{'url': 'https://public.vmm.pw/aeon/models/wd-v1-2-full-ema-pruned.ckpt'}]\n",
        "    # },\n",
        "    'Waifu Diffusion 1.3': {\n",
        "        'files': [{\n",
        "            'url': 'https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/wd-v1-3-float16.ckpt',\n",
        "            'args': ['-o', 'wd-v1-3-epoch09-float16.ckpt']\n",
        "        }]\n",
        "    },\n",
        "\n",
        "    # Trinart2\n",
        "    'Trinart Stable Diffusion v2 60,000 Steps': {\n",
        "        'files': [{'url': 'https://huggingface.co/naclbit/trinart_stable_diffusion_v2/resolve/main/trinart2_step60000.ckpt'}]\n",
        "    },\n",
        "    'Trinart Stable Diffusion v2 95,000 Steps': {\n",
        "        'files': [{'url': 'https://huggingface.co/naclbit/trinart_stable_diffusion_v2/resolve/main/trinart2_step95000.ckpt'}]\n",
        "    },\n",
        "    'Trinart Stable Diffusion v2 115,000 Steps': {\n",
        "        'files': [{'url': 'https://huggingface.co/naclbit/trinart_stable_diffusion_v2/resolve/main/trinart2_step115000.ckpt'}]\n",
        "    },\n",
        "\n",
        "    # Kinky c:\n",
        "    # 'gg1342_testrun1': {\n",
        "    #   'files': [{'url': 'https://public.vmm.pw/aeon/models/gg1342_testrun1_pruned.ckpt'}]\n",
        "    # },\n",
        "    # 'Hentai Diffusion RD1412': {\n",
        "    #   'files': [{\n",
        "    #     'url': 'https://public.vmm.pw/aeon/models/RD1412-pruned-fp16.ckpt',\n",
        "    #     'args': ['-o', 'hentai_diffusion-rd1412-pruned-fp32.ckpt']\n",
        "    #   }]\n",
        "    # },\n",
        "    # 'Bare Feet / Full Body b4_t16_noadd': {\n",
        "    #   'files': [{'url': 'https://public.vmm.pw/aeon/models/bf_fb_v3_t4_b16_noadd-ema-pruned-fp16.ckpt'}]\n",
        "    # },\n",
        "    # 'Lewd Diffusion 70k (epoch 2)': {\n",
        "    #   'files': [{'url': 'https://public.vmm.pw/aeon/models/LD-70k-2e-pruned.ckpt'}]\n",
        "    # },\n",
        "\n",
        "    # More kinky c:<\n",
        "    # 'Yiffy (epoch 18)': {\n",
        "    #   'files': [{'url': 'https://public.vmm.pw/aeon/models/yiffy-e18.ckpt'}]\n",
        "    # },\n",
        "    'Furry (epoch 4)': {\n",
        "        'files': [{'url': 'https://iwiftp.yerf.org/Furry/Software/Stable%20Diffusion%20Furry%20Finetune%20Models/Finetune%20models/furry_epoch4.ckpt'}]\n",
        "    },\n",
        "    'Zack3D Kinky v1': {\n",
        "        'files': [{'url': 'https://iwiftp.yerf.org/Furry/Software/Stable%20Diffusion%20Furry%20Finetune%20Models/Finetune%20models/Zack3D_Kinky-v1.ckpt'}]\n",
        "    },\n",
        "    # 'R34 (epoch 1)': {\n",
        "    #   'files': [{'url': 'https://public.vmm.pw/aeon/models/r34_e1.ckpt'}]\n",
        "    # },\n",
        "    # 'Pony Diffusion': {\n",
        "    #  'files': [{ 'url': 'https://public.vmm.pw/aeon/models/pony_sfw_80k_safe_and_suggestive_500rating_plus-pruned.ckpt'}]\n",
        "    # },\n",
        "    'Pokemon': {\n",
        "        'files': [{\n",
        "            'url': 'https://huggingface.co/justinpinkney/pokemon-stable-diffusion/resolve/main/ema-only-epoch%3D000142.ckpt',\n",
        "            'args': ['-o', 'pokemon-ema-pruned.ckpt']\n",
        "        }]\n",
        "    },\n",
        "\n",
        "    # Others...\n",
        "    'Dreambooth - Hiten': {\n",
        "        'files': [{'url': 'https://huggingface.co/BumblingOrange/Hiten/resolve/main/Hiten%20girl_anime_8k_wallpaper_4k.ckpt'}]\n",
        "    },\n",
        "}\n",
        "\n",
        "# @markdown ### ***모델(체크포인트) 선택***\n",
        "# @markdown - [모델 별 설명 및 다운로드 주소](https://rentry.org/sdmodels)\n",
        "CHECKPOINT = 'NAI - animefull-final-pruned' # @param ['NAI - animefull-final-pruned', 'NAI - animefull-latest', 'Waifu Diffusion 1.3', 'Trinart Stable Diffusion v2 60,000 Steps', 'Trinart Stable Diffusion v2 95,000 Steps', 'Trinart Stable Diffusion v2 115,000 Steps', 'Furry (epoch 4)', 'Zack3D Kinky v1', 'Pokemon', 'Dreambooth - Hiten'] {allow-input: true}\n",
        "\n",
        "# @markdown ### ***구글 드라이브 동기화를 사용할건지?***\n",
        "USE_GOOGLE_DRIVE = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown ### ***구글 드라이브 경로***\n",
        "GOOGLE_DRIVE_ROOT = 'SD'  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### ***파이썬 패키지를 아카이브할지?***\n",
        "# @markdown 구글 드라이브에 파이썬 패키지를 `.tar` 파일로 백업하고 실행할 땐 다시 해체함\n",
        "# @markdown <br>켜두면 런타임 날라갈 때마다 패키지 받는 일 줄어드니 켜는 걸 추천함\n",
        "ARCHIVE_PYTHON_PACKAGE = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown ### ***xformers 를 사용할지?***\n",
        "# @markdown 켜두면 10-15% 정도의 성능 향상을 ***보일 수도 있음***\n",
        "# @markdown <br>패키지를 직접 빌드하는데 30분에서 한 시간 정도 걸림\n",
        "# @markdown <br>구글 드라이브 동기화 아직 구현 안해둬서 개인 컴퓨터에서만 사용하는 걸 추천함\n",
        "USE_XFORMERS = False  # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown ### ***DeepDanbooru 를 사용할지?***\n",
        "USE_DEEPDANBOORU = True  # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 구글 드라이브 동기화\n",
        "# ==============================\n",
        "def mount_google_drive() -> None:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "    # 전체 경로 업데이트\n",
        "    update_path_to(os.path.join('/content/drive/MyDrive', GOOGLE_DRIVE_ROOT))\n",
        "\n",
        "    # 아카이브된 파이썬 패키지 경로 추가하기\n",
        "    path_to['packages_archive'] = f\"{path_to['workspace']}/packages.tar\"\n",
        "\n",
        "    # WebUI 에서 결과 디렉터리가 존재하지 않으면 오류를 반환하기 때문에 수동으로 만들어야됨\n",
        "    # TODO: 설정 파일(ui-config.json)로부터 경로 가져와서 만들기\n",
        "    subdirs = [\n",
        "        'extras-images',\n",
        "        'txt2img-images',\n",
        "        'txt2img-grids',\n",
        "        'img2img-images',\n",
        "        'img2img-grids'\n",
        "    ]\n",
        "\n",
        "    for subdir in subdirs:\n",
        "        os.makedirs(f\"{path_to['outputs']}/{subdir}\", exist_ok=True)\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 파일 다운로드\n",
        "# ==============================\n",
        "is_fetching_checkpoint = False\n",
        "\n",
        "\n",
        "def prepare_aria2() -> None:\n",
        "    execute_subprocess(\n",
        "        ['apt', 'install', '-qq', '-o=Dpkg::Use-Pty=0', '-y', 'aria2'])\n",
        "\n",
        "    # Aria2 설정\n",
        "    aria2_conf = \"\"\"\n",
        "summary-interval=10\n",
        "allow-overwrite=true\n",
        "always-resume=true\n",
        "disk-cache=64M\n",
        "continue=true\n",
        "min-split-size=8M\n",
        "max-concurrent-downloads=8\n",
        "max-connection-per-server=8\n",
        "max-overall-download-limit=0\n",
        "max-download-limit=0\n",
        "split=8\n",
        "seed-time=0\n",
        "\"\"\"\n",
        "\n",
        "    # Aria2 설정 파일 저장\n",
        "    os.makedirs(os.path.join(Path.home(), '.aria2'), exist_ok=True)\n",
        "    with open(Path.joinpath(Path.home(), '.aria2', 'aria2.conf'), \"w\") as f:\n",
        "        f.write(aria2_conf)\n",
        "\n",
        "\n",
        "def download(url: str, args=[]):\n",
        "    # anonfile CDN 주소 가져오기\n",
        "    if url.startswith('https://anonfiles.com/'):\n",
        "        matches = re.search('https://cdn-[^\\\"]+', requests.get(url).text)\n",
        "        if not matches:\n",
        "            raise Exception('anonfiles 에서 CDN 주소를 파싱하는데 실패했습니다')\n",
        "\n",
        "        url = matches[0]\n",
        "\n",
        "    # Aria2 로 모델 받기\n",
        "    log(f\"파일 다운로드를 시도합니다: {url}\")\n",
        "    execute_subprocess(['aria2c', *args, url])\n",
        "    log('파일을 성공적으로 받았습니다!')\n",
        "\n",
        "\n",
        "def download_checkpoint(checkpoint: str) -> None:\n",
        "    global is_fetching_checkpoint\n",
        "\n",
        "    # 이미 받는 중이라면 무시하기\n",
        "    if is_fetching_checkpoint:\n",
        "        return\n",
        "\n",
        "    is_fetching_checkpoint = True\n",
        "\n",
        "    try:\n",
        "        prepare_aria2()\n",
        "\n",
        "        # 선택한 체크포인트 정보 가져오기\n",
        "        if checkpoint in CHECKPOINTS:\n",
        "            checkpoint = CHECKPOINTS[checkpoint]\n",
        "        else:\n",
        "            # 미리 선언된 체크포인트가 아니라면 주소로써 사용하기\n",
        "            checkpoint = {'files': [{'url': checkpoint}]}\n",
        "\n",
        "        # Aria2 로 모델 받기\n",
        "        # TODO: 토렌트 마그넷 주소 지원\n",
        "        log(f\"파일 {len(checkpoint['files'])}개를 받습니다\")\n",
        "\n",
        "        for f in checkpoint['files']:\n",
        "            file = json.loads(json.dumps(f))\n",
        "\n",
        "            if 'args' not in file:\n",
        "                file['args'] = []\n",
        "\n",
        "            # 모델 받을 기본 디렉터리 경로 잡아주기\n",
        "            if '-d' not in file['args']:\n",
        "                file['args'] = [\n",
        "                    '-d', f\"{path_to['models']}/Stable-diffusion\", *file['args']]\n",
        "\n",
        "            download(**file)\n",
        "\n",
        "    finally:\n",
        "        is_fetching_checkpoint = False\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# Python 3.10 설치\n",
        "# ==============================\n",
        "def install_python_package(pkgs:List[str], args=['-q', '-I', '--progress-bar=off'],\n",
        "                           skip_if_has_package:List[str]=None, persist=False) -> None:\n",
        "    # 존재한다면 스킵할 패키지가 존재하는지 확인하기\n",
        "    if skip_if_has_package and len(filter_installed_python_packages([skip_if_has_package])) < 1:\n",
        "        log(f'{pkgs} 패키지가 이미 존재합니다, 설치를 넘깁니다')\n",
        "        return\n",
        "\n",
        "    # 영구 유지할 패키지는 외부 패키지 디렉터리에 저장하기\n",
        "    if persist:\n",
        "        args = [*args, f\"--target={path_to['packages']}\"]\n",
        "\n",
        "    log(f'{pkgs} 패키지가 존재하지 않습니다, 설치를 시도합니다')\n",
        "\n",
        "    execute_subprocess(['python3.10', '-m', 'pip', 'install', '--upgrade', 'setuptools'])\n",
        "    execute_subprocess(['python3.10', '-m', 'pip', 'install', '--prefer-binary', *args, *pkgs])\n",
        "\n",
        "\n",
        "def installed_python_packages() -> List[str]:\n",
        "    pkgs = !python3.10 -m pip list | tail -n+3 | cut -d' ' -f1\n",
        "    return pkgs\n",
        "\n",
        "\n",
        "def filter_installed_python_packages(pkgs:List[str]) -> List[str]:\n",
        "    installed_pkgs = installed_python_packages()\n",
        "    return [\n",
        "        p for p in pkgs if\n",
        "        # 빈 줄 제외\n",
        "        not p == ''\n",
        "\n",
        "        # 주석 처리된 패키지 제외\n",
        "        and not p.startswith('#')\n",
        "\n",
        "        # 설치된 패키지 제외\n",
        "        and re.search('[a-zA-Z0-9-_]+', p)[0].replace('_', '-') not in installed_pkgs\n",
        "    ]\n",
        "\n",
        "\n",
        "def setup_python() -> None:\n",
        "    if shutil.which('python3.10') is None:\n",
        "        log('Python 3.10 을 설치합니다')\n",
        "\n",
        "        execute_subprocess(['add-apt-repository', '-y', 'ppa:deadsnakes/ppa'])\n",
        "        execute_subprocess(['apt', 'update', '-qq', '-y'])\n",
        "        execute_subprocess(['apt', 'install', '-qq', '-o=Dpkg::Use-Pty=0',\n",
        "                           '-y', 'python3.10', 'python3.10-distutils', 'python3.10-dev'])\n",
        "        execute_subprocess(\n",
        "            'curl -sS https://bootstrap.pypa.io/get-pip.py | python3.10', shell=True)\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# WebUI 레포지토리 및 종속 패키지 설치\n",
        "# ==============================\n",
        "def setup_webui_repository() -> None:\n",
        "    need_clone = True\n",
        "\n",
        "    # 이미 디렉터리가 존재한다면 정상적인 레포인지 확인하기\n",
        "    if isdir(path_to['repo']):\n",
        "        try:\n",
        "            commit = !cd {path_to['repo']} && git rev-parse HEAD\n",
        "            int(commit[0], 16)  # 16진수가 아니라면(커밋 해시가 없을 때) raise 됨\n",
        "            need_clone = False\n",
        "\n",
        "            # 레포지토리 풀링 (업데이트)\n",
        "            log('레포지토리를 풀 합니다')\n",
        "            execute_subprocess(['git', 'reset', '--hard'], cwd=path_to['repo'])\n",
        "            execute_subprocess(['git', 'pull'], cwd=path_to['repo'])\n",
        "\n",
        "            # 모델 용량이 너무 커서 코랩 메모리 할당량을 초과하면 프로세스를 강제로 초기화됨\n",
        "            # 이를 해결하기 위해선 모델 맵핑 위치를 VRAM으로 변경해줘야함\n",
        "            # Thanks to https://gist.github.com/td2sk/e32a39344537fb3cd756ef4abdd3d371\n",
        "            # TODO: 코랩에서만 발생하는 문제인지?\n",
        "            execute_subprocess([\n",
        "                'sed',\n",
        "                '-i',\n",
        "                '''s/map_location=\"cpu\"/map_location=torch.device(\"cuda\")/g''',\n",
        "                f\"{path_to['repo']}/modules/sd_models.py\"\n",
        "            ])\n",
        "\n",
        "        except ValueError:\n",
        "            log('정상적인 git 프로젝트가 아닙니다, 기존 레포지토리 디렉터리를 제거합니다')\n",
        "\n",
        "    if need_clone:\n",
        "        log('레포지토리를 클론합니다')\n",
        "        shutil.rmtree(path_to['repo'], ignore_errors=True)\n",
        "        execute_subprocess(['git', 'clone', 'https://github.com/AUTOMATIC1111/stable-diffusion-webui', path_to['repo']])\n",
        "\n",
        "\n",
        "def setup_webui_dependencies() -> None:\n",
        "    log('WebUI 종속 패키지를 확인합니다')\n",
        "\n",
        "    execute_subprocess(\n",
        "        ['apt', 'install', '-qq', '-o=Dpkg::Use-Pty=0', '-y', 'build-essential', 'libgl1'])\n",
        "\n",
        "    # 설치된 PyTorch 가 최신 GPU 지원하지 않을 수 있기 때문에 최신 버전으로 받아주기\n",
        "    install_python_package(\n",
        "        ['torch', 'torchvision'],\n",
        "        [\n",
        "            '--ignore-installed',\n",
        "            '--extra-index-url=https://download.pytorch.org/whl/cu116'\n",
        "        ],\n",
        "        skip_if_has_package='torch',\n",
        "        persist=True\n",
        "    )\n",
        "\n",
        "    # 라이브러리 수동 설치, 조금 병신 같지만 어쩔 수 없음...\n",
        "    # https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/f7c787eb7c295c27439f4fbdf78c26b8389560be/launch.py#L17-L18\n",
        "    install_python_package(\n",
        "        ['git+https://github.com/TencentARC/GFPGAN.git@8d2447a2d918f8eba5a4a01463fd48e45126a379'],\n",
        "        skip_if_has_package='gfpgan',\n",
        "        persist=True\n",
        "    )\n",
        "\n",
        "    install_python_package(\n",
        "        ['git+https://github.com/openai/CLIP.git@d50d76daa670286dd6cacf3bcd80b5e4823fc8e1'],\n",
        "        skip_if_has_package='clip',\n",
        "        persist=True\n",
        "    )\n",
        "\n",
        "    # 레포지토리 종속 패키지 받기 (requirements_versions.txt)\n",
        "    pkgs = !cat {path_to['repo']}/requirements_versions.txt\n",
        "    pkgs = filter_installed_python_packages(pkgs)\n",
        "\n",
        "    if len(pkgs) > 0:\n",
        "        install_python_package(pkgs, persist=True)\n",
        "\n",
        "    # xformers 패키지 설치하기\n",
        "    # https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Xformers\n",
        "    # TODO: 구글 드라이브 동기화\n",
        "    if USE_XFORMERS and 'xformers' not in installed_python_packages():\n",
        "        log('xformers 레포지토리를 가져옵니다')\n",
        "        shutil.rmtree('xformers', ignore_errors=True)\n",
        "        execute_subprocess(['git', 'clone', 'https://github.com/facebookresearch/xformers.git'])\n",
        "        execute_subprocess(['git', 'submodule', 'update', '--init', '--recursive'], cwd='xformers')\n",
        "        execute_subprocess(['python3.10', '-m', 'pip', 'install', '-r', 'requirements.txt'], cwd='xformers')\n",
        "\n",
        "        log('xformers 패키지를 빌드하고 설치합니다')\n",
        "        execute_subprocess(['python3.10', '-m', 'pip', 'install', 'setuptools==49.6.0'])\n",
        "        execute_subprocess(['python3.10', '-m', 'pip', 'install', '-e', '.'], cwd='xformers')\n",
        "\n",
        "    # deepdanbooru 종속 패키지 설치하기\n",
        "    # https://github.com/KichangKim/DeepDanbooru/blob/master/requirements.txt\n",
        "    if USE_DEEPDANBOORU:\n",
        "        install_python_package(\n",
        "            ['git+https://github.com/KichangKim/DeepDanbooru.git@edf73df4cdaeea2cf00e9ac08bd8a9026b7a7b26#egg=deepdanbooru[tensorflow]'],\n",
        "            skip_if_has_package='deepdanbooru',\n",
        "            persist=True\n",
        "        )\n",
        "\n",
        "        install_python_package(['tensorflow'], skip_if_has_package=['tensorflow'], persist=True)\n",
        "        install_python_package(['tensorflow-io'], skip_if_has_package=['tensorflow_io'], persist=True)\n",
        "\n",
        "# ==============================\n",
        "# WebUI 실행\n",
        "# ==============================\n",
        "def parse_webui_output(out:str) -> bool:\n",
        "    matches = re.search('https://\\d+\\.gradio\\.app', out)\n",
        "    if matches:\n",
        "        dialog(f'''\n",
        "        <p>성공적으로 웹UI를 실행했습니다!</p>\n",
        "        <p><a target=\"_blank\" href=\"{matches[0]}\">여기를 눌러 창을 열 수 있습니다</a></p>\n",
        "        ''')\n",
        "\n",
        "\n",
        "def start_webui() -> None:\n",
        "    global running_subprocess\n",
        "\n",
        "    if running_subprocess is not None:\n",
        "        if 'launch.py' in running_subprocess.args:\n",
        "            log('이미 실행 중인 웹UI를 종료하고 다시 시작합니다')\n",
        "            running_subprocess.kill()\n",
        "            running_subprocess = None\n",
        "\n",
        "        raise ('이미 다른 프로세스가 실행 중입니다, 잠시 후에 실행해주세요')\n",
        "\n",
        "    # 명령어 인자\n",
        "    args = [\n",
        "        '--share',\n",
        "\n",
        "        # 동적 경로들\n",
        "        f\"--ckpt-dir={path_to['models']}/Stable-diffusion\",\n",
        "        f\"--embeddings-dir={path_to['embeddings']}\",\n",
        "        f\"--codeformer-models-path={path_to['models']}/Codeformer\",\n",
        "        f\"--gfpgan-models-path={path_to['models']}/GFPGAN\",\n",
        "        f\"--esrgan-models-path={path_to['models']}/ESRGAN\",\n",
        "        f\"--bsrgan-models-path={path_to['models']}/BSRGAN\",\n",
        "        f\"--realesrgan-models-path={path_to['models']}/RealESRGAN\",\n",
        "        f\"--scunet-models-path={path_to['models']}/ScuNET\",\n",
        "        f\"--swinir-models-path={path_to['models']}/SwinIR\",\n",
        "        f\"--ldsr-models-path={path_to['models']}/LDSR\",\n",
        "\n",
        "        f\"--ui-config-file={path_to['ui_config_file']}\",\n",
        "        f\"--ui-settings-file={path_to['ui_settings_file']}\",\n",
        "    ]\n",
        "\n",
        "    if USE_XFORMERS:\n",
        "        args = [*args, '--xformers', '--force-enable-xformers']\n",
        "\n",
        "    if USE_DEEPDANBOORU:\n",
        "        args = [*args, '--deepdanbooru']\n",
        "\n",
        "    execute_subprocess(\n",
        "        ['python3.10', 'launch.py', *args],\n",
        "        parser=parse_webui_output,\n",
        "        cwd=path_to['repo'],\n",
        "        env={'PYTHONUNBUFFERED': '1', **os.environ}\n",
        "    )\n",
        "\n",
        "\n",
        "def generate_report() -> str:\n",
        "    packages = !pip freeze\n",
        "    packages_310 = !python3.10 -m pip freeze\n",
        "\n",
        "    import platform\n",
        "    import traceback\n",
        "    from distutils.spawn import find_executable\n",
        "\n",
        "    def format_list(value):\n",
        "        if isinstance(value, dict):\n",
        "            return '\\n'.join(map(lambda kv: f'{kv[0]}: {kv[1]}', value.items()))\n",
        "        else:\n",
        "            return '\\n'.join(value)\n",
        "\n",
        "    payload = f\"\"\"\n",
        "{html_logger.raw}\n",
        "{traceback.format_exc()}\n",
        "## platform\n",
        "{platform.platform()}\n",
        "\n",
        "## {sys.executable}\n",
        "{format_list(packages)}\n",
        "\n",
        "## {find_executable('python3.10')}\n",
        "{format_list(packages_310)}\n",
        "\n",
        "## options\n",
        "CHECKPOINT: {CHECKPOINT}\n",
        "USE_GOOGLE_DRIVE: {USE_GOOGLE_DRIVE}\n",
        "GOOGLE_DRIVE_ROOT: {GOOGLE_DRIVE_ROOT}\n",
        "ARCHIVE_PYTHON_PACKAGE: {ARCHIVE_PYTHON_PACKAGE}\n",
        "USE_XFORMERS: {USE_XFORMERS}\n",
        "USE_DEEPDANBOORU: {USE_DEEPDANBOORU}\n",
        "\n",
        "## paths\n",
        "{format_list(path_to)}\n",
        "\n",
        "## models\n",
        "{format_list(glob.glob(f\"{path_to['models']}/**/*\"))}\n",
        "\"\"\"\n",
        "\n",
        "    res = requests.post('https://hastebin.com/documents',\n",
        "                        data=payload.encode('utf-8'))\n",
        "\n",
        "    return f\"https://hastebin.com/{json.loads(res.text)['key']}\"\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 자 드게제~\n",
        "# ==============================\n",
        "try:\n",
        "    # 코랩 폼 입력 란을 생성을 위한 코드\n",
        "    # log(', '.join(map(lambda s:f\"'{s}'\", CHECKPOINTS.keys())))\n",
        "\n",
        "    # 인터페이스 출력\n",
        "    btn_download_checkpoint = widgets.Button(description='체크포인트 받기')\n",
        "    btn_download_checkpoint.on_click(\n",
        "        lambda _: download_checkpoint(CHECKPOINT)\n",
        "    )\n",
        "\n",
        "    # btn_report = widgets.Button(description='보고서 만들기')\n",
        "    # btn_report.on_click(\n",
        "    #   lambda e: dialog(f'보고서를 만들었습니다, 아래 주소를 복사해주세요<br>{generate_report()}')\n",
        "    # )\n",
        "\n",
        "    display(\n",
        "        widgets.VBox([\n",
        "            html_dialog,\n",
        "            btn_download_checkpoint,\n",
        "            # btn_report,\n",
        "            widgets.Box(\n",
        "                [html_logger],\n",
        "                # layout=widgets.Layout(max_height='300px')\n",
        "            )\n",
        "        ])\n",
        "    )\n",
        "\n",
        "    # 구글 드라이브 마운트\n",
        "    if USE_GOOGLE_DRIVE:\n",
        "        mount_google_drive()\n",
        "\n",
        "        # 아카이브한 파이썬 패키지 해체하기\n",
        "        if ARCHIVE_PYTHON_PACKAGE and isfile(path_to['packages_archive']):\n",
        "            log('아카이브된 파이썬 패키지가 존재합니다, 패키지 디렉터리에 해체합니다')\n",
        "\n",
        "            try:\n",
        "                # 기존 패키지 디렉터리 제거하기\n",
        "                shutil.rmtree(path_to['packages'], ignore_errors=True)\n",
        "                os.makedirs(path_to['packages'])\n",
        "\n",
        "                execute_subprocess(['tar', 'xf', path_to['packages_archive'], '-C', path_to['packages']])\n",
        "            except:\n",
        "                log('아카이브 해체에 실패했습니다, 파일이 손상된 것 같습니다', styles={'color': 'red'})\n",
        "\n",
        "    # 체크포인트가 없다면 다운로드 시도하기\n",
        "    force_download_checkpoint = True\n",
        "\n",
        "    for p in Path(f\"{path_to['models']}/Stable-diffusion\").glob('**/*.ckpt'):\n",
        "        # aria2 로 받다만 파일은 무시하기\n",
        "        if isfile(f'{p}.aria2'):\n",
        "            continue\n",
        "\n",
        "        force_download_checkpoint = False\n",
        "        break\n",
        "\n",
        "    if force_download_checkpoint:\n",
        "        log('체크포인트가 존재하지 않습니다, 자동으로 받아옵니다')\n",
        "        download_checkpoint(CHECKPOINT)\n",
        "\n",
        "    # 파이썬 설치\n",
        "    setup_python()\n",
        "\n",
        "    # WebUI 레포지토리 및 종속 패키지 설치\n",
        "    setup_webui_repository()\n",
        "    setup_webui_dependencies()\n",
        "\n",
        "    # 파이썬 패키지 아카이브하기\n",
        "    if ARCHIVE_PYTHON_PACKAGE and 'packages_archive' in path_to:\n",
        "        log('파이썬 패키지를 아카이브합니다')\n",
        "        execute_subprocess([\n",
        "            'tar', '-c', '-f', path_to['packages_archive'],\n",
        "            '-C', path_to['packages'],\n",
        "            '.'\n",
        "        ])\n",
        "\n",
        "    # TODO: 결과, 하이퍼네트웍스 디렉터리 경로를 지정하는 인자가 없음, 임시로 심볼릭으로 연결\n",
        "    if USE_GOOGLE_DRIVE:\n",
        "        log('심볼릭 링크를 만듭니다')\n",
        "\n",
        "        if not islink(f\"{path_to['repo']}/models/hypernetworks\"):\n",
        "            shutil.rmtree(f\"{path_to['repo']}/models/hypernetworks\", ignore_errors=True)\n",
        "            execute_subprocess(['ln', '-sf', f\"{path_to['models']}/hypernetworks\", f\"{path_to['repo']}/models/hypernetworks\"])\n",
        "        if not islink(f\"{path_to['repo']}/outputs\"):\n",
        "            shutil.rmtree(f\"{path_to['repo']}/outputs\", ignore_errors=True)\n",
        "            execute_subprocess(['ln', '-sf', path_to['outputs'], f\"{path_to['repo']}/outputs\"])\n",
        "\n",
        "    # WebUI 실행\n",
        "    start_webui()\n",
        "\n",
        "# ^c 종료 무시하기\n",
        "except KeyboardInterrupt:\n",
        "    pass\n",
        "\n",
        "# 오류 발생하면 보고서 생성하고 표시하기\n",
        "except:\n",
        "    report_url = generate_report()\n",
        "    dialog(f'''\n",
        "    <p>작업 중 오류가 발생했습니다, 아래 주소를 복사해 올려주세요</p>\n",
        "    <p><strong>{report_url}</strong></p>\n",
        "  ''', preset='error')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "2XtKWLG8DIln",
        "jJNoIIZxDLeb"
      ],
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
